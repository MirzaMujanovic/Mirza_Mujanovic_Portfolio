[["job-interview-task-social-media-data.html", "4 Job-interview task: Social media data 4.1 Data 4.2 How many authors have interacted in the database? 4.3 Which one is the most used media? 4.4 What is the percentage of each used media? 4.5 What is the percentage of positive, negative and neutral comments? 4.6 What is the average sentiment in Twitter? 4.7 Visalisation task", " 4 Job-interview task: Social media data Figure 4.1: Foto from Google This tasks is a part of a case study given as a job-exercise. Here I aim to demonstrate how one can solve analytics task with R very efficiently. The exact task reads as follow: At the company we create clarity, out of the chaos of digital noise. Our big data analytics platform and services combine technology and human expertise to help organizations around the world achieve clear and actionable insights every day. In our team of data scientists, you will become part of the human layer that develops specialized expertise for organizations, we explore hypotheses and dig deeper into big data assets and uncover actionable insights. This assignment is designed to give you a glimpse of some of the challenges you will be facing in this role. Please be aware there are no perfect solutions - for us, its more important to see how you find solutions, process your ideas, structure your thoughts and how you make your decision paths. Be creative but realistic about whats possible. We are thrilled to get to know a bit more about the way you solve tasks. 4.1 Data library(XML) library(tibble) library(tidyverse) library(readr) library(kableExtra) library(ggplot2) library(plotly) As usual, we first load in data by using readxl_xlsx() function and take a glimpse at it: data&lt;-readxl::read_xlsx(&quot;data/Alto-Case_Study_Dataset (1).xlsx&quot;) glimpse(data) ## Rows: 4,287 ## Columns: 12 ## $ ID &lt;dbl&gt; 109537653, 109556421, 109537642, 109543173, 1095... ## $ Autors &lt;chr&gt; &quot;josiehoulston&quot;, &quot;O2&quot;, &quot;MuccaMadness&quot;, &quot;bhups&quot;, ... ## $ TITLE &lt;chr&gt; &quot;@O2 no signal again. Third day of interruption&quot;... ## $ LINK &lt;chr&gt; &quot;http://twitter.com/josiehoulston/statuses/60394... ## $ BODY &lt;chr&gt; &quot;@O2 no signal again. Third day of interruption&quot;... ## $ PUBDATE &lt;dttm&gt; 2015-05-28 17:29:47, 2015-05-28 17:29:30, 2015-... ## $ `PERSONAL-WEBSITE` &lt;chr&gt; &quot;http://twitter.com/josiehoulston&quot;, &quot;http://www.... ## $ COUNTRY &lt;chr&gt; &quot;gb&quot;, &quot;gb&quot;, &quot;gb&quot;, &quot;gb&quot;, &quot;gb&quot;, &quot;gb&quot;, &quot;gb&quot;, &quot;gb&quot;, ... ## $ `PUBLISHER-ID` &lt;dbl&gt; 11, 11, 11, 140, 11, 11, 11, 11, 10, 11, 11, 11,... ## $ `PUBLISHER-NAME` &lt;chr&gt; &quot;Twitter&quot;, &quot;Twitter&quot;, &quot;Twitter&quot;, &quot;GiffGaff&quot;, &quot;Tw... ## $ `ORIG-ID` &lt;chr&gt; &quot;603946276951031808&quot;, &quot;603946202216955904&quot;, &quot;603... ## $ SENTIMENT &lt;dbl&gt; 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0,... The data has 12 features and 4287 observations. Let us inspect missing values: apply(is.na(data),2,sum) ## ID Autors TITLE LINK ## 0 0 0 0 ## BODY PUBDATE PERSONAL-WEBSITE COUNTRY ## 5 0 15 0 ## PUBLISHER-ID PUBLISHER-NAME ORIG-ID SENTIMENT ## 0 0 0 0 There are 5 missing entries in BODY column and 15 in PERSONAL-WEBISTE. Consequently, we will remove these entries. data&lt;-(data[complete.cases(data), ]) data ## Warning: `...` is not empty. ## ## We detected these problematic arguments: ## * `needs_dots` ## ## These dots only exist to allow future extensions and should be empty. ## Did you misspecify an argument? ## # A tibble: 4,267 x 12 ## ID Autors TITLE LINK BODY PUBDATE `PERSONAL-WEBSI~ COUNTRY ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dttm&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1.10e8 josie~ @O2 ~ http~ @O2 ~ 2015-05-28 17:29:47 http://twitter.~ gb ## 2 1.10e8 O2 @luk~ http~ @luk~ 2015-05-28 17:29:30 http://www.o2.c~ gb ## 3 1.10e8 Mucca~ @Sar~ http~ @Sar~ 2015-05-28 17:29:15 http://twitter.~ gb ## 4 1.10e8 bhups Re: ~ http~ Chec~ 2015-05-28 17:29:00 https://communi~ gb ## 5 1.10e8 helen~ @Ash~ http~ @Ash~ 2015-05-28 17:28:54 http://twitter.~ gb ## 6 1.10e8 21Ayu~ RT @~ http~ RT @~ 2015-05-28 17:28:36 http://twitter.~ gb ## 7 1.10e8 O2tou~ RT @~ http~ RT @~ 2015-05-28 17:28:14 http://O2Touch.~ gb ## 8 1.18e8 O2Aca~ RT @~ http~ RT @~ 2015-05-28 17:28:08 http://www.o2ac~ gb ## 9 1.49e8 Dave ~ Re: ~ http~ cant~ 2015-05-28 17:28:04 https://www.fac~ gb ## 10 1.10e8 Emmie~ @The~ http~ @The~ 2015-05-28 17:27:52 http://twitter.~ gb ## # ... with 4,257 more rows, and 4 more variables: `PUBLISHER-ID` &lt;dbl&gt;, ## # `PUBLISHER-NAME` &lt;chr&gt;, `ORIG-ID` &lt;chr&gt;, SENTIMENT &lt;dbl&gt; Finally, our data has the following structure: glimpse(data) ## Rows: 4,267 ## Columns: 12 ## $ ID &lt;dbl&gt; 109537653, 109556421, 109537642, 109543173, 1095... ## $ Autors &lt;chr&gt; &quot;josiehoulston&quot;, &quot;O2&quot;, &quot;MuccaMadness&quot;, &quot;bhups&quot;, ... ## $ TITLE &lt;chr&gt; &quot;@O2 no signal again. Third day of interruption&quot;... ## $ LINK &lt;chr&gt; &quot;http://twitter.com/josiehoulston/statuses/60394... ## $ BODY &lt;chr&gt; &quot;@O2 no signal again. Third day of interruption&quot;... ## $ PUBDATE &lt;dttm&gt; 2015-05-28 17:29:47, 2015-05-28 17:29:30, 2015-... ## $ `PERSONAL-WEBSITE` &lt;chr&gt; &quot;http://twitter.com/josiehoulston&quot;, &quot;http://www.... ## $ COUNTRY &lt;chr&gt; &quot;gb&quot;, &quot;gb&quot;, &quot;gb&quot;, &quot;gb&quot;, &quot;gb&quot;, &quot;gb&quot;, &quot;gb&quot;, &quot;gb&quot;, ... ## $ `PUBLISHER-ID` &lt;dbl&gt; 11, 11, 11, 140, 11, 11, 11, 11, 10, 11, 11, 11,... ## $ `PUBLISHER-NAME` &lt;chr&gt; &quot;Twitter&quot;, &quot;Twitter&quot;, &quot;Twitter&quot;, &quot;GiffGaff&quot;, &quot;Tw... ## $ `ORIG-ID` &lt;chr&gt; &quot;603946276951031808&quot;, &quot;603946202216955904&quot;, &quot;603... ## $ SENTIMENT &lt;dbl&gt; 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0,... 4.2 How many authors have interacted in the database? My first task is to identify the number of authors who had interaction with the database. In order to do so, we will use column Autors. This column has a class character, so none class conversion is necessary. Let us inspect number of authors asked: # Total number of interactions interacted length(data$Autors) ## [1] 4267 # Number of authors interacted with the data base length(unique(data$Autors)) ## [1] 2672 Out of total 4267 interactions, 2672 are unique. Thus, we can say that the number of unique interactions is 2672. # Authors (task1&lt;-as.data.frame(table(data$Autors)) %&gt;% rename(Authors=Var1, Count=Freq) %&gt;% arrange(desc(Count))) %&gt;% head(10)%&gt;% kableExtra::kable(escape = T) %&gt;% kable_paper(c(&quot;hover&quot;), full_width = F) Authors Count O2 258 SoldoutGigs 33 O2JobsFeed 25 yobigdawg 14 mathew40 12 Cleoriff 10 O2AcademyOxford 10 PocutDaraa 10 MI5 9 JimGilroy 8 Let us visualize it: library(ggplot2) task1 %&gt;% arrange(desc(Count)) %&gt;% head(10) %&gt;% ggplot(aes(x=reorder(Authors,Count),y=Count,fill=Authors)) + geom_bar(stat=&quot;identity&quot;)+ labs(x=&quot;Authors&quot;,y=&quot;Count&quot;,title = &quot;Top 10 Most Active Authors on Twitter&quot;)+ coord_flip() The most active authors on Twitter are: O2 as the most active by far SoldoutGigs and O2JobsFeed are following. 4.3 Which one is the most used media? media &lt;- as.data.frame(table(data$`PUBLISHER-NAME`)) colnames(media) &lt;- c(&quot;Media&quot;,&quot;Freq&quot;) # Top 10 media used media &lt;- head(media[order(media$Freq,decreasing = T),],10) media%&gt;% kableExtra::kable(escape = T) %&gt;% kableExtra::kable_paper(c(&quot;hover&quot;), full_width = F) Media Freq 7 Twitter 3798 3 GiffGaff 204 1 Facebook 177 6 O2 UK 59 9 YouTube 20 5 Instagram 4 8 Vodafone UK 3 2 Flickr 1 4 Google+ 1 # Plot ggplot(media,aes(fill=Media)) + geom_bar(stat = &quot;identity&quot;,aes(reorder(Media,Freq),Freq)) + coord_flip() + theme(legend.position = &quot;none&quot;)+ scale_y_log10()+ labs(x=&quot;Media&quot;, y=&quot;Count&quot;,title = &quot;Top 10 Most Used Media&quot;) The most used media is Twitter, followed by GiffGaff and Facebook. 4.4 What is the percentage of each used media? media_perc&lt;-as.data.frame(prop.table(table(data$`PUBLISHER-NAME`))) media_perc$Freq &lt;- round(media_perc$Freq*100,4) head(media_perc[order(media_perc$Freq,decreasing = T),],10) %&gt;% rename(Author=Var1,Percentage=Freq)%&gt;% kable(escape = T) %&gt;% kable_paper(c(&quot;hover&quot;), full_width = F) Author Percentage 7 Twitter 89.0087 3 GiffGaff 4.7809 1 Facebook 4.1481 6 O2 UK 1.3827 9 YouTube 0.4687 5 Instagram 0.0937 8 Vodafone UK 0.0703 2 Flickr 0.0234 4 Google+ 0.0234 4.5 What is the percentage of positive, negative and neutral comments? as.data.frame(prop.table(table(data$SENTIMENT))*100) %&gt;% rename(Sentiment=Var1,Percentage=Freq) %&gt;% arrange(desc(Percentage))%&gt;% kable(escape = T) %&gt;% kable_paper(c(&quot;hover&quot;), full_width = F) Sentiment Percentage 0 76.7518163 -1 11.5537849 1 10.7804078 2 0.5390204 -2 0.3749707 Based on the analysis, around 77% of comments are neutral, 12% slightly negative and 11% slightly positive. Percentage of extremely positive or extremely negative comments is in total around 0.8%. 4.6 What is the average sentiment in Twitter? mean(data$SENTIMENT) ## [1] -0.004452777 4.7 Visalisation task Make a scatter plot of the database using 3 variables. Two of them are provided here: Media: Twitter, Facebook and Instagram. Visibility: total of comments and average sentiment. By combining information about publishers (Twitter, Facebook and Instagram), date of publishing, sentiment and average sentiment we are able to create a multiple line plot to explain sentiment in each publisher in the given period of a day. First we filtered data to retain publishers such as Twitter, Facebook, Instagram, GiffGaff and O2 UK. Subsequently, we pivot the table so that the final sheet look like this (only first 6 rows): plot&lt;-subset(data,`PUBLISHER-NAME`==&quot;Twitter&quot; | `PUBLISHER-NAME`==&quot;Facebook&quot; | `PUBLISHER-NAME`==&quot;Instagram&quot; | `PUBLISHER-NAME`==&quot;GiffGaff&quot; | `PUBLISHER-NAME`==&quot;O2 UK&quot;) %&gt;% rename(Publisher=`PUBLISHER-NAME`,Sentiment=SENTIMENT) %&gt;% group_by(Publisher,PUBDATE) %&gt;% mutate(Date=PUBDATE, Publisher=as.factor(Publisher))%&gt;% summarise(Sentiment=mean(Sentiment)) plot%&gt;% head()%&gt;% kable(escape = T) %&gt;% kable_paper(c(&quot;hover&quot;), full_width = F) Publisher PUBDATE Sentiment Facebook 2015-05-27 17:30:00 0 Facebook 2015-05-27 17:31:11 1 Facebook 2015-05-27 17:31:43 0 Facebook 2015-05-27 17:38:51 -1 Facebook 2015-05-27 17:45:00 -1 Facebook 2015-05-27 17:45:48 -1 In the first column are publishers we retained. The second column is the exact date and time of publishing the comment. Finally, the last column denotes the sentiment score associated with each comment. We are in a position to vizualise sentiment scores across platforms in the given observation time. ggplot(plot, aes(x = PUBDATE, y = Sentiment)) + geom_point(aes(color = Publisher), size = 1.5) + labs(title = &quot;How is sentiment across platform?&quot;,x=&quot;&quot;,subtitle =&quot;Number of comments: FB=177; GiffGaff=204; IG=4; O2 UK=59; TW=3798&quot;)+ facet_grid(Publisher~.)+ theme_bw() We could see that Twitter is the most balanced publisher, as there are not many deviations. In addition, Facebook and Twitter seem to mimic each other to some extent. Some good news were published on May 27 after 18 PM as the sentiment scores for Twitter, Fabook and O2 UK in this period were extremely positive. "]]
