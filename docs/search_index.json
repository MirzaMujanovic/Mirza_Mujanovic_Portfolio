[["charles-book-club.html", "6 Charles Book Club 6.1 The Problem 6.2 A Possible Solution 6.3 Background Information 6.4 Recency - Frequency - Monetary Analysis 6.5 Assignment 6.6 Visaul exploration 6.7 Response rate in training data 6.8 Prediction of response rate of 1 clusters 6.9 Prediction of response rate of 3 clusters 6.10 Reference", " 6 Charles Book Club The Charles Book Club case was derived, with the assistance of Ms. Vinni Bhandari, from The Bookbinders Club, a Case Study in Database Marketing, prepared by Nissan Levin and Jacob Zahavi, Tel Aviv University The Charles Book Club (CBC) was established in December 1986 on the premise that a book club could differentiate itself through a deep understanding of its customer base and by delivering uniquely tailored offerings. CBC focused on selling specialty books by direct marketing through a variety of channels, including media advertising (TV, magazines, newspapers) and mailing. CBC is strictly a distributor and does not publish any of the books that it sells. In line with its commitment to understanding its customer base, CBC built and maintained a detailed database about its club members. Upon enrollment, readers were required to fill out an insert and mail it to CBC. Through this process, CBC created an active database of 500,000 readers; most were acquired through advertising in specialty magazines. Historically, book clubs offered their readers different types of membership programs. Two common membership programs are the continuity and negative option programs, which are both extended contractual relationships between the club and its members. Under a continuity program, a reader signs up by accepting an offer of several books for just a few dollars (plus shipping and handling) and an agreement to receive a shipment of one or two books each month thereafter at more-standard pricing. The continuity program is most common in the childrens book market, where parents are willing to delegate the rights to the book club to make a selection, and much of the clubs prestige depends on the quality of its selections. In a negative option program, readers get to select how many and which additional books they would like to receive. However, the clubs selection of the month is delivered to them automatically unless they specifically mark no on their order form by a deadline date. Negative option programs sometimes result in customer dissatisfaction and always give rise to significant mailing and processing costs. In an attempt to combat these trends, some book clubs have begun to offer books on a positive option basis, but only to specific segments of their customer base that are likely to be receptive to specific offers. Rather than expanding the volume and coverage of mailings, some book clubs are beginning to use database-marketing techniques to target customers more accurately. Information contained in their databases is used to identify who is most likely to be interested in a specific offer. This information enables clubs to design special programs carefully tailored to meet their customer segments varying needs. 6.1 The Problem CBC sent mailings to its club members each month containing the latest offerings. On the surface, CBC appeared very successful: mailing volume was increasing, book selection was diversifying and growing,and their customer database was increasing. However, their bottom-line profits were falling. The decreasing profits led CBC to revisit their original plan of using database marketing to improve mailing yields and to stay profitable. 6.2 A Possible Solution CBC embraced the idea of deriving intelligence from their data to allow them to know their customers better and enable multiple targeted campaigns where each target audience would receive appropriate mailings. CBCs management decided to focus its efforts on the most profitable customers and prospects, and to design targeted marketing strategies to best reach them. The two processes they had in place were: 1. Customer acquisition: New members would be acquired by advertising in specialty magazines, newspapers, and on TV. Direct mailing and telemarketing would contact existing club members. Every new book would be offered to club members before general advertising. 2. Data collection: All customer responses would be recorded and maintained in the database. Any information not being collected that is critical would be requested from the customer. For each new title, they decided to use a two-step approach: Conduct a market test involving a random sample of 4000 customers from the database to enable analysis of customer responses. The analysis would create and calibrate response models for the current book offering. Based on the response models, compute a score for each customer in the database. Use this score and a cutoff value to extract a target customer list for direct-mail promotion. Targeting promotions was considered to be of prime importance. Other opportunities to create successful marketing campaigns based on customer behavior data (returns, inactivity, complaints, compliments, etc.) would be addressed by CBC at a later stage. 6.3 Background Information A new title, The Art History of Florence, is ready for release. CBC sent a test mailing to a random sample of 4000 customers from its customer base. The customer responses have been collated with past purchase data. The dataset was randomly partitioned into three parts: Training Data (1800 customers): initial data to be used to fit models, Validation Data (1400 customers): holdout data used to compare the performance of different models, and Test Data (800 customers): data to be used only after a final model has been selected to estimate the probable performance of the model when it is deployed. Each row (or case) in the spreadsheet (other than the header) corresponds to one market test customer. Each column is a variable, with the header row giving the name of the variable. 6.4 Recency - Frequency - Monetary Analysis The segmentation process in database marketing aims to partition customers in a list of prospects into homogeneous groups (segments) that are similar with respect to buying behavior. The homogeneity criterion we need for segmentation is the propensity to purchase the offering. However, since we cannot measure this attribute, we use variables that are plausible indicators of this propensity. In the direct marketing business, the most commonly used variables are the RFM variables: R = recency, time since last purchase F = frequency, number of previous purchases from the company over a period M = monetary, amount of money spent on the companys products over a period The assumption is that the more recent the last purchase, the more products bought from the company in the past, and the more money spent in the past buying the companys products, the more likely the customer is to purchase the product offered. The 1800 observations in the dataset were divided into recency, frequency, and monetary categories as follows: Recency: Recency Recode 02 months Rcode = 1 36 months Rcode = 2 712 months Rcode = 3 13 months and up Rcode = 4 Frequency: Frequency Recode 1 book Fcode = 1 2 books Fcode = 2 3 books Fcode = 3 Monetary: Monetary Recode 0  25 Mcode = 1 2650 Mcode = 2 51100 Mcode = 3 101200 Mcode = 4 201 and up Mcode = 5 Note: Montary values are denoted in USD 6.5 Assignment Partition the data into training (60%) and validation (40%). Use seed = 1. What is the response rate for the training data customers taken as a whole? What is the response rate for each of the 4×5×3 = 60 combinations of RFM categories? Which combinations have response rates in the training data that are above the overall response in the training data? Before we answer the question, let us explore the data set: ## Rows: 4,000 ## Columns: 24 ## $ Seq. &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15,... ## $ ID. &lt;int&gt; 25, 29, 46, 47, 51, 60, 61, 79, 81, 90, 95, 100, 1... ## $ Gender &lt;int&gt; 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1,... ## $ M &lt;int&gt; 297, 128, 138, 228, 257, 145, 190, 187, 252, 240, ... ## $ R &lt;int&gt; 14, 8, 22, 2, 10, 6, 16, 14, 10, 6, 2, 2, 4, 14, 4... ## $ F &lt;int&gt; 2, 2, 7, 1, 1, 2, 1, 1, 1, 3, 4, 3, 1, 1, 2, 9, 6,... ## $ FirstPurch &lt;int&gt; 22, 10, 56, 2, 10, 12, 16, 14, 10, 20, 20, 18, 4, ... ## $ ChildBks &lt;int&gt; 0, 0, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 2, 2,... ## $ YouthBks &lt;int&gt; 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,... ## $ CookBks &lt;int&gt; 1, 0, 2, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 3, 2,... ## $ DoItYBks &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... ## $ RefBks &lt;int&gt; 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,... ## $ ArtBks &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,... ## $ GeogBks &lt;int&gt; 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0,... ## $ ItalCook &lt;int&gt; 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,... ## $ ItalAtlas &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,... ## $ ItalArt &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,... ## $ Florence &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,... ## $ Related.Purchase &lt;int&gt; 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 6, 2,... ## $ Mcode &lt;int&gt; 5, 4, 4, 5, 5, 4, 4, 4, 5, 5, 5, 5, 5, 4, 5, 5, 5,... ## $ Rcode &lt;int&gt; 4, 3, 4, 1, 3, 2, 4, 4, 3, 2, 1, 1, 2, 4, 2, 4, 4,... ## $ Fcode &lt;int&gt; 2, 2, 3, 1, 1, 2, 1, 1, 1, 3, 3, 3, 1, 1, 2, 3, 3,... ## $ Yes_Florence &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,... ## $ No_Florence &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1,... ## ## 2 4 6 8 10 12 14 16 18 20 22 24 26 28 30 32 34 36 ## 294 280 278 324 524 474 534 477 94 82 102 80 75 70 96 84 84 48 First, we will convert the response variable to factor class. data$Yes_Florence &lt;- factor(data$Yes_Florence, labels = c(&quot;No&quot;,&quot;Yes&quot;),levels = c(0:1)) data$No_Florence &lt;-factor(data$No_Florence, labels = c(&quot;No&quot;,&quot;Yes&quot;),levels = c(0:1)) Second, we would need to compute RFM score by merging three scores into one cell. # Calculating RFM score data$RFM_score&lt;- paste(data$Rcode,data$Fcode,data$Mcode) data$RFM_score &lt;- gsub(&quot; &quot;,&quot;&quot;,data$RFM_score) data$RFM_score&lt;-as.factor(data$RFM_score) data[1:10,&quot;RFM_score&quot;] ## [1] 425 324 434 115 315 224 414 414 315 235 ## 51 Levels: 111 112 113 114 115 122 123 124 125 132 133 134 135 211 212 ... 435 Now we will proceed with data partition. For that we will use sample() function, where we indicate rownames and the number of randomly selected row numbers we want to separate from the remaining data set. In our case, out of 4000 rows (Customers), we will randomly assign 2400 to train data set, and the rest to test data. # Train data set.seed(1) trainIndex &lt;- caret::createDataPartition(data$Florence, p = .6, list = FALSE, times = 1) train_data &lt;- data[ trainIndex,] The remaining part of the data set will be assigned to the validation data set. # Validation set validation_data &lt;- data[-trainIndex,] 6.6 Visaul exploration It would be beneficial to inspect relationship between recency, frequency and monetary value in the whole data set before we continue. A quite convenient way to do it is a heatmap. There we can plot all three variables at the same time and inspect the monetary value (= amount spend in the time frame observed) of each customer based on his/her frequency and recency. Customers who purchased more frequently generated more revenue compared to those who visited less frequently. Further, customers who spent the most are not the most recent ones: the heaviest spenders are the frequent ones, but they havent made a purchase 3 to 6 months. Usually, the customers who visited in the recent past (0-2 months) are more likely to return compared to those who made a purchase some time ago as most of those could potentially be lost customers. As such, higher revenue would be associated with most recent visits, but wee see that is not really the case here. This could be related to the nature of books as products and the fact that they are not frequently purchased items such as daily products for instance. Nevertheless, it would definitively be worth to consider giving incentives to these customers who spent the most, but the company has not heard of them for 3-6 months. A legit question for better understanding of our target group would be about the difference in recency of customers who responded to advertising of Florence. data %&gt;% rename(Revenue=M, Response=Yes_Florence) %&gt;% ggplot(aes(x=Response,y=F,fill=Response))+ geom_boxplot()+ labs(x=&quot;Response to Campaign&quot;,y=&quot;Frequency (Number of Purchases)&quot;,title = &quot;How Frequent Are Customers Interested in &#39;Florence&#39;?&quot;, subtitle = &quot;Boxplots depicting frequency of respondents and non-respondents&quot;)+ stat_summary(fun.y=mean, geom=&quot;point&quot;, shape=20, size=10, color=&quot;red&quot;, fill=&quot;red&quot;) + theme_bw() ## Warning: `fun.y` is deprecated. Use `fun` instead. There seem to be difference in means of the two groups. Non-respondents are somewhat less frequent customers, while respondents belong to more frequent customers. Let us see about their recency. Customers who responded to the Florence campaign have on average lower recency than customers who did not respond. All in all, we can conclude that customers who responded to the campaign are, on average, slightly more frequent and recent than customers who did not respond to campaign. 6.7 Response rate in training data Now we can start with addressing the first question: what is the response rate for training data customers taken as whole? Let us now inspect the response rate for training data customers. Response rate of customers from the training data is around 9%. ## [1] 0.08708333 6.8 Prediction of response rate of 1 clusters Now we would need to inspect response rates from all 60 (possible) combinations, and compare them with the overall one. ## # A tibble: 51 x 2 ## RFM_score Response_rate ## &lt;fct&gt; &lt;dbl&gt; ## 1 111 0 ## 2 112 0 ## 3 113 0 ## 4 114 0.25 ## 5 115 0.115 ## 6 122 0.5 ## 7 123 0 ## 8 124 0 ## 9 125 0.118 ## 10 132 1 ## # ... with 41 more rows The following RFM scores indicate response rate higher than 9%: ## # A tibble: 19 x 3 ## RFM_score Response_rate n ## &lt;fct&gt; &lt;dbl&gt; &lt;int&gt; ## 1 114 0.25 16 ## 2 115 0.115 26 ## 3 122 0.5 2 ## 4 125 0.118 17 ## 5 132 1 1 ## 6 135 0.170 53 ## 7 211 0.333 3 ## 8 212 0.333 9 ## 9 213 0.136 22 ## 10 215 0.179 28 ## 11 223 0.167 24 ## 12 224 0.114 35 ## 13 225 0.114 44 ## 14 233 0.333 6 ## 15 234 0.146 41 ## 16 235 0.151 93 ## 17 323 0.1 40 ## 18 335 0.153 215 ## 19 433 0.118 17 Suppose that we decide to send promotional mail only to the above average RFM combinations identified in part. Now we should compute the response rate in the validation data using these above average combinations. 6.9 Prediction of response rate of 3 clusters Let us now segment our customers in 3 different segments: Segment 1: RFM combinations that have response rates that exceed twice the overall response rate Segment 2: RFM combinations that exceed the overall response rate but do not exceed twice that rate Segment 3: the remaining RFM combinations ## # A tibble: 51 x 3 ## RFM_score Response_rate Cluster ## &lt;fct&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 111 0 RR_Below ## 2 112 0 RR_Below ## 3 113 0 RR_Below ## 4 114 0.25 RR_Twice ## 5 115 0.115 RR_Above ## 6 122 0.5 RR_Twice ## 7 123 0 RR_Below ## 8 124 0 RR_Below ## 9 125 0.118 RR_Above ## 10 132 1 RR_Twice ## # ... with 41 more rows We classified RFM scores based on response rate into 3 segments. Now we will identify customers with those RFM scores in the validation set, and compare predicted/expected response rate from the training data set with the actual response rate. By visual inspection we could see that predicted response rates are above the true ones in two out of 3 segments. Customers who had response rate at least twice the initial response rate (9%) were expected to have around 22% response rate, but the true response rate is the half at around 17% response rate. Similarly, the RFM prediction in case of customers who had response rate between 9 and 18% was slightly inaccurate as well(predicted 13% vs 9% true response rate). The only case where true response rate exceeded the predicted response rate is the segment with the response rate below 9%. However, in order to find out how well is our model, we will create a lift chart. It helps us determine how effectively we can proceed with our campaign. We aim at selecting a relatively small number of customers and getting a relatively large portion of respondents. For a given number of customers, the lift curve value on the y-axis will shows us how much better we are doing compared to random choice of customers. Based on the gain chart, prediction based on our RFM model performs a bit better than baseline, i.e. random guessing. More specifically, if we select top 20% cases based on our model, we would attract 29% of the target customers, i.e. customers who would respond to our marketing campaign. Although we managed to create a model that performs better than just guessing, in the further analyses we will try out other approaches, such as logistic regression, that may provide us better results. 6.10 Reference Shmueli, G., Bruce, P. C., Yahav, I., Patel, N. R., &amp; Lichtendahl, K. C. (2018). Data mining for business analytics: Concepts, techniques, and applications in R. "]]
